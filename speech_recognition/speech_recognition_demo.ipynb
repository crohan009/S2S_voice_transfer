{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_recognition version - 3.6.3\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import struct\n",
    "import speech_recognition as sr\n",
    "print(\"speech_recognition version - {}\".format(sr.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for audio clipping, playing, and recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip16(x):    \n",
    "    # Clipping for 16 bits\n",
    "    if x > 32767:\n",
    "        x = 32767\n",
    "    elif x < -32768:\n",
    "        x = -32768\n",
    "    else:\n",
    "        x = x        \n",
    "    return int(x)\n",
    "\n",
    "def play_wav(filename):\n",
    "\n",
    "    import wave\n",
    "    import pyaudio\n",
    "    import time\n",
    "\n",
    "    wf = wave.open(filename, 'rb')\n",
    "    CHANNELS = wf.getnchannels()\n",
    "    RATE = wf.getframerate() \n",
    "    WIDTH = wf.getsampwidth() \n",
    "\n",
    "    def my_callback(input_string, block_size, time_info, status):\n",
    "        output_string = wf.readframes(block_size)\n",
    "        return (output_string, pyaudio.paContinue)\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format = p.get_format_from_width(WIDTH),\n",
    "                    channels = CHANNELS,\n",
    "                    rate = RATE,\n",
    "                    input = False,\n",
    "                    output = True,\n",
    "                    stream_callback = my_callback)\n",
    "\n",
    "    print('* Playing audio file: ' + filename)\n",
    "    stream.start_stream()\n",
    "\n",
    "    while stream.is_active():\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    print('Finished.')\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()\n",
    "    \n",
    "def record_wav(filename='test_01.wav', CHANNELS = 1, RATE = 16000, WIDTH = 2, GAIN = 1.0):\n",
    "\n",
    "    def my_callback_fun(binary_input_data, block_size, time_info, status):\n",
    "        input_tuple = struct.unpack('h', binary_input_data)\n",
    "        output_sample = clip16(GAIN * input_tuple[0])\n",
    "        output_list.append(output_sample)\n",
    "        return(binary_input_data, pyaudio.paContinue)\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Set PyAudio format\n",
    "    PA_format = p.get_format_from_width(WIDTH)\n",
    "\n",
    "    stream = p.open(format = PA_format,\n",
    "                    channels = CHANNELS,\n",
    "                    rate = RATE,\n",
    "                    input = True,\n",
    "                    output = False,\n",
    "                    frames_per_buffer = 1,\n",
    "                    stream_callback = my_callback_fun)\n",
    "\n",
    "    output_list = []\n",
    "\n",
    "    stream.start_stream()\n",
    "    print('* Start recording')\n",
    "\n",
    "    time.sleep(10.0)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    print('* Finish recording')\n",
    "\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Convert output signal to binary signal to write to wave file \n",
    "    output_string = struct.pack('h'*len(output_list), *output_list)\n",
    "\n",
    "    # write data into wav file\n",
    "    wf = wave.open(filename, 'w')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(WIDTH)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(output_string)\n",
    "    wf.close()\n",
    "\n",
    "    print('* Audio saved to file: ' + filename)\n",
    "\n",
    "filename = 'test_01.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record an audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Start recording\n",
      "* Finish recording\n",
      "* Audio saved to file: test_01.wav\n"
     ]
    }
   ],
   "source": [
    "record_wav(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Playing audio file: test_01.wav\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "play_wav(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognised speech : \n",
      "\n",
      "this is a speech recognition demo using python speech recognition library and tacotron 2\n",
      "\n",
      "Time taken for speech recognition : 4.698 seconds\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "test_file = sr.AudioFile(filename)\n",
    "\n",
    "with test_file as source:\n",
    "    audio = r.record(source)\n",
    "# type(audio)\n",
    "\n",
    "start = time.time()\n",
    "text = r.recognize_google(audio)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recognised speech : \\n\\n{}\".format(text))\n",
    "print(\"\\nTime taken for speech recognition : {} seconds\".format( round(end-start, 3) ))\n",
    "\n",
    "f = open(\"test_01.txt\", \"w\")\n",
    "print(text, file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running End-to-End TTS Evaluation. Model: Tacotron-2\n",
      "Synthesizing mel-spectrograms from text..\n",
      "loaded model at logs-Tacotron-2/taco_pretrained/tacotron_model.ckpt-35000\n",
      "Hyperparameters:\n",
      "  allow_clipping_in_normalization: True\n",
      "  attention_dim: 128\n",
      "  attention_filters: 32\n",
      "  attention_kernel: (31,)\n",
      "  cbhg_conv_channels: 128\n",
      "  cbhg_highway_units: 128\n",
      "  cbhg_highwaynet_layers: 4\n",
      "  cbhg_kernels: 8\n",
      "  cbhg_pool_size: 2\n",
      "  cbhg_projection: 256\n",
      "  cbhg_projection_kernel_size: 3\n",
      "  cbhg_rnn_units: 128\n",
      "  cin_channels: 80\n",
      "  cleaners: english_cleaners\n",
      "  clip_for_wavenet: True\n",
      "  clip_mels_length: True\n",
      "  cross_entropy_pos_weight: 20\n",
      "  cumulative_weights: True\n",
      "  decoder_layers: 2\n",
      "  decoder_lstm_units: 1024\n",
      "  embedding_dim: 512\n",
      "  enc_conv_channels: 512\n",
      "  enc_conv_kernel_size: (5,)\n",
      "  enc_conv_num_layers: 3\n",
      "  encoder_lstm_units: 256\n",
      "  fmax: 7600\n",
      "  fmin: 55\n",
      "  frame_shift_ms: None\n",
      "  freq_axis_kernel_size: 3\n",
      "  gate_channels: 256\n",
      "  gin_channels: -1\n",
      "  griffin_lim_iters: 60\n",
      "  hop_size: 275\n",
      "  input_type: raw\n",
      "  kernel_size: 3\n",
      "  layers: 20\n",
      "  leaky_alpha: 0.4\n",
      "  log_scale_min: -32.23619130191664\n",
      "  log_scale_min_gauss: -16.11809565095832\n",
      "  mask_decoder: False\n",
      "  mask_encoder: True\n",
      "  max_abs_value: 4.0\n",
      "  max_iters: 2000\n",
      "  max_mel_frames: 1000\n",
      "  max_time_sec: None\n",
      "  max_time_steps: 11000\n",
      "  min_level_db: -100\n",
      "  n_fft: 2048\n",
      "  n_speakers: 5\n",
      "  natural_eval: False\n",
      "  normalize_for_wavenet: True\n",
      "  num_freq: 1025\n",
      "  num_mels: 80\n",
      "  out_channels: 2\n",
      "  outputs_per_step: 1\n",
      "  postnet_channels: 512\n",
      "  postnet_kernel_size: (5,)\n",
      "  postnet_num_layers: 5\n",
      "  power: 1.5\n",
      "  predict_linear: True\n",
      "  preemphasis: 0.97\n",
      "  preemphasize: True\n",
      "  prenet_layers: [256, 256]\n",
      "  quantize_channels: 65536\n",
      "  ref_level_db: 20\n",
      "  rescale: True\n",
      "  rescaling_max: 0.999\n",
      "  residual_channels: 128\n",
      "  sample_rate: 22050\n",
      "  signal_normalization: True\n",
      "  silence_threshold: 2\n",
      "  skip_out_channels: 128\n",
      "  smoothing: False\n",
      "  split_on_cpu: True\n",
      "  stacks: 2\n",
      "  stop_at_any: True\n",
      "  symmetric_mels: True\n",
      "  tacotron_adam_beta1: 0.9\n",
      "  tacotron_adam_beta2: 0.999\n",
      "  tacotron_adam_epsilon: 1e-06\n",
      "  tacotron_batch_size: 32\n",
      "  tacotron_clip_gradients: True\n",
      "  tacotron_data_random_state: 1234\n",
      "  tacotron_decay_learning_rate: True\n",
      "  tacotron_decay_rate: 0.5\n",
      "  tacotron_decay_steps: 50000\n",
      "  tacotron_dropout_rate: 0.5\n",
      "  tacotron_final_learning_rate: 1e-05\n",
      "  tacotron_gpu_start_idx: 0\n",
      "  tacotron_initial_learning_rate: 0.001\n",
      "  tacotron_num_gpus: 1\n",
      "  tacotron_random_seed: 5339\n",
      "  tacotron_reg_weight: 1e-07\n",
      "  tacotron_scale_regularization: False\n",
      "  tacotron_start_decay: 50000\n",
      "  tacotron_swap_with_cpu: False\n",
      "  tacotron_synthesis_batch_size: 1\n",
      "  tacotron_teacher_forcing_decay_alpha: 0.0\n",
      "  tacotron_teacher_forcing_decay_steps: 280000\n",
      "  tacotron_teacher_forcing_final_ratio: 0.0\n",
      "  tacotron_teacher_forcing_init_ratio: 1.0\n",
      "  tacotron_teacher_forcing_mode: constant\n",
      "  tacotron_teacher_forcing_ratio: 1.0\n",
      "  tacotron_teacher_forcing_start_decay: 10000\n",
      "  tacotron_test_batches: None\n",
      "  tacotron_test_size: 0.05\n",
      "  tacotron_zoneout_rate: 0.1\n",
      "  train_with_GTA: False\n",
      "  trim_fft_size: 512\n",
      "  trim_hop_size: 128\n",
      "  trim_silence: True\n",
      "  trim_top_db: 23\n",
      "  upsample_activation: LeakyRelu\n",
      "  upsample_conditional_features: True\n",
      "  upsample_scales: [5, 5, 11]\n",
      "  upsample_type: 1D\n",
      "  use_bias: True\n",
      "  use_lws: False\n",
      "  use_speaker_embedding: True\n",
      "  wavenet_adam_beta1: 0.9\n",
      "  wavenet_adam_beta2: 0.999\n",
      "  wavenet_adam_epsilon: 1e-08\n",
      "  wavenet_batch_size: 8\n",
      "  wavenet_clip_gradients: False\n",
      "  wavenet_data_random_state: 1234\n",
      "  wavenet_decay_rate: 0.5\n",
      "  wavenet_decay_steps: 300000\n",
      "  wavenet_dropout: 0.05\n",
      "  wavenet_ema_decay: 0.9999\n",
      "  wavenet_gpu_start_idx: 0\n",
      "  wavenet_init_scale: 1.0\n",
      "  wavenet_learning_rate: 0.0001\n",
      "  wavenet_lr_schedule: exponential\n",
      "  wavenet_num_gpus: 1\n",
      "  wavenet_random_seed: 5339\n",
      "  wavenet_swap_with_cpu: False\n",
      "  wavenet_synthesis_batch_size: 20\n",
      "  wavenet_test_batches: None\n",
      "  wavenet_test_size: 0.0441\n",
      "  wavenet_warmup: 4000.0\n",
      "  wavenet_weight_normalization: False\n",
      "  win_size: 1100\n",
      "Constructing model: Tacotron\n",
      "initialisation done /gpu:0\n",
      "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
      "  Train mode:               False\n",
      "  Eval mode:                False\n",
      "  GTA mode:                 False\n",
      "  Synthesis mode:           True\n",
      "  Input:                    (?, ?)\n",
      "  device:                   0\n",
      "  embedding:                (?, ?, 512)\n",
      "  enc conv out:             (?, ?, 512)\n",
      "  encoder out:              (?, ?, 512)\n",
      "  decoder out:              (?, ?, 80)\n",
      "  residual out:             (?, ?, 512)\n",
      "  projected residual out:   (?, ?, 80)\n",
      "  mel out:                  (?, ?, 80)\n",
      "  linear out:               (?, ?, 1025)\n",
      "  <stop_token> out:         (?, ?)\n",
      "  Tacotron Parameters       29.016 Million.\n",
      "Loading checkpoint: logs-Tacotron-2/taco_pretrained/tacotron_model.ckpt-35000\n",
      "INFO:tensorflow:Restoring parameters from logs-Tacotron-2/taco_pretrained/tacotron_model.ckpt-35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Synthesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crohan009/anaconda3/lib/python3.6/site-packages/librosa/util/utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthesized mel spectrograms at tacotron_output/eval\n",
      "Tacotron TTS synthesis complete!\n",
      "\n",
      "Time taken for speech generation : 19.922 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run -i \"synthesize.py\" --model='Tacotron-2' --mode='eval' --text_list=test_01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Playing audio file: tacotron_output/logs-eval/wavs/wav-batch_0_sentence_0-linear.wav\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# filename = \"wavenet_output/wavs/wavenet-audio-mel-batch_0_sentence_0.wav\"\n",
    "\n",
    "filename = \"tacotron_output/logs-eval/wavs/wav-batch_0_sentence_0-linear.wav\"\n",
    "play_wav(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken for TTS generation : 0.644 seconds\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "start = time.time()\n",
    "tts = gTTS(text=text, lang='en')\n",
    "end = time.time()\n",
    "print(\"\\nTime taken for TTS generation : {} seconds\".format( round(end-start, 3) ))\n",
    "tts.save('sample.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer # Load the required library\n",
    "\n",
    "mixer.init()\n",
    "mixer.music.load('sample.mp3')\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
